<!DOCTYPE html>

<meta charset=utf-8>
<title>The Baliocene Apocrypha</title>
<link rel=stylesheet href=../backup.css>

<body class=post>

<header>
</header>
<article class=text id=p-156313571146>
<header>
<p><time datetime=2017-01-24T16:03:59Z>01/24/2017 11:03:59 AM</time>
<a class=llink href=../posts/156313571146.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2Hb0yzA>●</a>
<a href=https://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2>⬀</a>
<a href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>⬈</a>
</header>
<h2>A Challenge: Question 2</h2>
<p><a href="http://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p>My favorite thing about the <a href="https://thingofthings.wordpress.com/2016/10/20/itt-social-justice-10/">ITT </a>is the way people answer question 2 “

What is the true reason, deep down, that you believe what you believe? What piece of evidence, test, or line of reasoning would convince you that you’re wrong about your ideology?”

</p>
<p>I’m certain every single respondent has thought deeply about what they believe. They’ve seen studies that back them up, thought about ethical principles, and seen the effects of oppression first hand. But when asked “why do you really believe this? what swayed you so much that it would change your mind if it was contradicted”… they often dissolve into vagueness and “everything shows I’m right!” Everything, of course, can never be disproven.</p>
<p>It’s a fascinating insight into how ideology works. Ideology isn’t formed by realizing our terminal values, or reading a study, it’s a much more osmotic experience than that. It involves quasi-believing things because so many other people we know believe them, and not questioning them *too* much because doing so is uncomfortable (both socially, and to our own identity as a good person.) Like <a href="https://srconstantin.wordpress.com/2016/10/20/ra/">Ra</a>, ideology hates it when you try to pin down terms and reasons too precisely.</p>
<p>So. Let’s do that. Here is my challenge to any rebloggers: <b>What is the true reason deep down that you believe what you believe? What evidence could convince you that you were wrong?</b></p>
<p>I’ll start.</p>
<hr><p>This tumblr is arguing the humanist viewpoint, so I’ll focus on why I’m a humanist, and what could sway me into other philosophies (specifically: parochial tribalism, anti-human universalism, or rights based liberalism and materialism.)</p>
<p>My terminal value is not special. It’s basically happy people, with an emphasis on complex and interesting lives and societies. My own personal goal is to find a button that increases human happiness no matter how much you push it, and to keep pushing it until it breaks.</p>
<p>It turns out that most of the things that we think increase human happiness, such as having better living conditions or more money, don’t really. And even our attempts to build up economies so that people have more stuff, are horribly complicated and unpredictable. I am distinctly unimpressed with a lot of the rationalist projects in this regard, and I suspect they will spend decades trying to find ways to improve the happiness of others with material interventions, and rarely feel they have made much success. There will still be misery everywhere, even after billions are spent. (If rationalist interventions started making a measurable and sizable impact in the amount of misery in the world, that would be evidence to change my view.) (Yes I saw <a href="http://slatestarcodex.com/2016/01/10/slow-but-steady/">Scott’s chart about malaria interventions</a>. I approve of malaria interventions. And the euphoria in the comments only emphasized to me how many rationalists are insecure about whether this project of theirs is having any results.)</p>
<p>Additionally, a lot of the rules we set down about how we should treat each other should increase human happiness, but mostly make humans miserable as they fight over the rules, and the rules are enforced haphazardly, with some receiving the extreme brunt of enforcement and others being afraid there isn’t enough enforcement. Which is why I am skeptical of rights based liberalism, and will continue to be until it is shown to be a better social technology than primitive tribalism.</p>
<p>The button that does work, that in my experience does make people reliably feel better, is listening to them and one-on-one interaction. Humans are social animals, and humans have very unique individual experiences. Respecting that individual complexity, and giving them social validation, seems the most reliably way to increase happiness, even if only on a very small scale.</p>
<p>If listening and validation are shown to be in the long run net-negative in happiness (if for instance, they operate like a drug that gives you a high that you then grow tolerant for) then I would be skeptical of that button.<br/>If there is no button that can reliably increase human happiness, well that would say a great deal about the chaotic nature of the human condition, which fundamentally validates my anti-categorical humanism.</p>
<p>But basically… if any button on the human psyche is shown to have reliable results - peer reviewed and consistently replicated - about how to affect people and make them happy, I would throw my philosophy out the window and pursue that. My current stance is a result of failure to find anything like that.</p>
<p>Now, humanism might just be speciesist, and it’s possible I don’t give enough credit to non-humans and dehumanized subjects. By appreciating complexity, I may be favoring people who’ve had interesting lives over people who have been so beaten down by the system that they will always be boring to me. This is a real risk and why I dabble in universalism elsewhere. But for now, my interactions with any human have shown that no matter how degraded they have been by society, they’re still as intelligent and social as the richest person I’ve met when you just listen to them for 10 minutes. If this were shown not to be the case statistically, I’d feel guilty about the inherent elitism of humanism, and I’d focus more on a philosophy that tries to exalt the most degraded and inhuman subjects.</p>
<p>Similarly for species, there seems a large gap in cognitive quality between humans and any other creature. If some species existed that were just somewhat less intelligent than humans but still identifiable as having a subjective experience in there, I’d have to look into a much more gradient focused definition of sentience and moral agency.<br/></p>
</blockquote>
<p><a class="tumblelog" href="https://tmblr.co/mz00oSVg_TogMX7aKjMrhQA">@jadagul</a> ‘s statement</p>
<blockquote><p>

I have a basically unshakeable conviction that people are mostly decent, and will treat most people well, and would like me to be happy. And following that belief has served me well.<br/>If I ever lost that belief, I would have to seriously rethink my ethics–my current position of trust-by-default would make a lot less sense, and I would probably find it much harder to sustain universal love and acceptance.

<br/></p></blockquote>
<p>from their (he? she? I don’t know) <a href="http://jadagul.tumblr.com/post/156300960938/bambamramfan-said-id-be-interested-in-your">post here</a>, reminded me of the above challenge. More people should do it!</p>
</blockquote>
<p>“But basically… if any button on the human psyche is shown to have 
reliable results - peer reviewed and consistently replicated - about how
 to affect people and make them happy, I would throw my philosophy out 
the window and pursue that. My current stance is a result of failure to 
find anything like that.”</p><p>&hellip;I think this means that you have to have an answer to “why not wireheading?”</p><p>Yeah, I know, it’s the most sophomoric of objections.  But wireheading <i>is </i>a thing, and it <i>does</i> reliably make people happy without them developing a tolerance.  The first-order problem with it for philosophers, in cynical terms, is that from the outside it creates something that looks less like our normal models of happiness than like drug addiction.  If you have non-hedonic terminal values, it’s very easy to explain why it’s not good enough.  But you seem to be working at a project where any conceivable result is going to look very weird from the standpoint of a normal person with normal assumptions.  So, uh, what’s wrong with the answer you’ve got?<br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/moral%20philosophy>#moral philosophy</a>
 — 25 notes — <a title=Source href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>bambamramfan</a></footer>
</article>

<!DOCTYPE html>

<meta charset=utf-8>
<title>The Baliocene Apocrypha</title>
<link rel=stylesheet href=../backup.css>

<body class=post>

<header>
</header>
<article class=text id=p-156358549336>
<header>
<p><time datetime=2017-01-25T16:18:33Z>01/25/2017 11:18:33 AM</time>
<a class=llink href=../posts/156358549336.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HdiXzO>●</a>
<a href=https://bambamramfan.tumblr.com/post/156313876367/a-challenge-question-2>⬀</a>
<a href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>⬈</a>
</header>
<h2>A Challenge: Question 2</h2>
<p><a href="http://bambamramfan.tumblr.com/post/156313876367/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://balioc.tumblr.com/post/156313571146/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p>My favorite thing about the <a href="https://thingofthings.wordpress.com/2016/10/20/itt-social-justice-10/">ITT </a>is the way people answer question 2 “

What is the true reason, deep down, that you believe what you believe? What piece of evidence, test, or line of reasoning would convince you that you’re wrong about your ideology?”

</p>
<p>I’m certain every single respondent has thought deeply about what they believe. They’ve seen studies that back them up, thought about ethical principles, and seen the effects of oppression first hand. But when asked “why do you really believe this? what swayed you so much that it would change your mind if it was contradicted”… they often dissolve into vagueness and “everything shows I’m right!” Everything, of course, can never be disproven.</p>
<p>It’s a fascinating insight into how ideology works. Ideology isn’t formed by realizing our terminal values, or reading a study, it’s a much more osmotic experience than that. It involves quasi-believing things because so many other people we know believe them, and not questioning them *too* much because doing so is uncomfortable (both socially, and to our own identity as a good person.) Like <a href="https://srconstantin.wordpress.com/2016/10/20/ra/">Ra</a>, ideology hates it when you try to pin down terms and reasons too precisely.</p>
<p>So. Let’s do that. Here is my challenge to any rebloggers: <b>What is the true reason deep down that you believe what you believe? What evidence could convince you that you were wrong?</b></p>
<p>I’ll start.</p>
<hr><p>This tumblr is arguing the humanist viewpoint, so I’ll focus on why I’m a humanist, and what could sway me into other philosophies (specifically: parochial tribalism, anti-human universalism, or rights based liberalism and materialism.)</p>
<p>My terminal value is not special. It’s basically happy people, with an emphasis on complex and interesting lives and societies. My own personal goal is to find a button that increases human happiness no matter how much you push it, and to keep pushing it until it breaks.</p>
<p>It turns out that most of the things that we think increase human happiness, such as having better living conditions or more money, don’t really. And even our attempts to build up economies so that people have more stuff, are horribly complicated and unpredictable. I am distinctly unimpressed with a lot of the rationalist projects in this regard, and I suspect they will spend decades trying to find ways to improve the happiness of others with material interventions, and rarely feel they have made much success. There will still be misery everywhere, even after billions are spent. (If rationalist interventions started making a measurable and sizable impact in the amount of misery in the world, that would be evidence to change my view.) (Yes I saw <a href="http://slatestarcodex.com/2016/01/10/slow-but-steady/">Scott’s chart about malaria interventions</a>. I approve of malaria interventions. And the euphoria in the comments only emphasized to me how many rationalists are insecure about whether this project of theirs is having any results.)</p>
<p>Additionally, a lot of the rules we set down about how we should treat each other should increase human happiness, but mostly make humans miserable as they fight over the rules, and the rules are enforced haphazardly, with some receiving the extreme brunt of enforcement and others being afraid there isn’t enough enforcement. Which is why I am skeptical of rights based liberalism, and will continue to be until it is shown to be a better social technology than primitive tribalism.</p>
<p>The button that does work, that in my experience does make people reliably feel better, is listening to them and one-on-one interaction. Humans are social animals, and humans have very unique individual experiences. Respecting that individual complexity, and giving them social validation, seems the most reliably way to increase happiness, even if only on a very small scale.</p>
<p>If listening and validation are shown to be in the long run net-negative in happiness (if for instance, they operate like a drug that gives you a high that you then grow tolerant for) then I would be skeptical of that button.<br/>If there is no button that can reliably increase human happiness, well that would say a great deal about the chaotic nature of the human condition, which fundamentally validates my anti-categorical humanism.</p>
<p>But basically… if any button on the human psyche is shown to have reliable results - peer reviewed and consistently replicated - about how to affect people and make them happy, I would throw my philosophy out the window and pursue that. My current stance is a result of failure to find anything like that.</p>
<p>Now, humanism might just be speciesist, and it’s possible I don’t give enough credit to non-humans and dehumanized subjects. By appreciating complexity, I may be favoring people who’ve had interesting lives over people who have been so beaten down by the system that they will always be boring to me. This is a real risk and why I dabble in universalism elsewhere. But for now, my interactions with any human have shown that no matter how degraded they have been by society, they’re still as intelligent and social as the richest person I’ve met when you just listen to them for 10 minutes. If this were shown not to be the case statistically, I’d feel guilty about the inherent elitism of humanism, and I’d focus more on a philosophy that tries to exalt the most degraded and inhuman subjects.</p>
<p>Similarly for species, there seems a large gap in cognitive quality between humans and any other creature. If some species existed that were just somewhat less intelligent than humans but still identifiable as having a subjective experience in there, I’d have to look into a much more gradient focused definition of sentience and moral agency.<br/></p>
</blockquote>
<p><a class="tumblelog" href="https://tmblr.co/mz00oSVg_TogMX7aKjMrhQA">@jadagul</a> ‘s statement</p>
<blockquote><p>

I have a basically unshakeable conviction that people are mostly decent, and will treat most people well, and would like me to be happy. And following that belief has served me well.<br/>If I ever lost that belief, I would have to seriously rethink my ethics–my current position of trust-by-default would make a lot less sense, and I would probably find it much harder to sustain universal love and acceptance.

<br/></p></blockquote>
<p>from their (he? she? I don’t know) <a href="http://jadagul.tumblr.com/post/156300960938/bambamramfan-said-id-be-interested-in-your">post here</a>, reminded me of the above challenge. More people should do it!</p>
</blockquote>
<p>“But basically… if any button on the human psyche is shown to have 
reliable results - peer reviewed and consistently replicated - about how
 to affect people and make them happy, I would throw my philosophy out 
the window and pursue that. My current stance is a result of failure to 
find anything like that.”</p>
<p>…I think this means that you have to have an answer to “why not wireheading?”</p>
<p>Yeah, I know, it’s the most sophomoric of objections.  But wireheading <i>is </i>a thing, and it <i>does</i> reliably make people happy without them developing a tolerance.  The first-order problem with it for philosophers, in cynical terms, is that from the outside it creates something that looks less like our normal models of happiness than like drug addiction.  If you have non-hedonic terminal values, it’s very easy to explain why it’s not good enough.  But you seem to be working at a project where any conceivable result is going to look very weird from the standpoint of a normal person with normal assumptions.  So, uh, what’s wrong with the answer you’ve got?<br/></p>
</blockquote>
<p>I’d want to see the literature on existing wireheading technology as it is now. I’m not really aware of it, and how it works would matter a lot.</p>
<p>The perspective I mention is more to say “lots of people say their idea makes humanity better off, but then does not hold up under empirical verification on a consistent basis.” This is a frequent enough occurrence that it’s a good default stance towards a lot of social engineering and direct neurochemical futzing. Wearing the humanist mask, I find this fact existentially interesting.</p>
<p>Faced with the actual wireheading dilemma, I would probably say that the complexity of life has to exist to be happy. If wireheading makes you a simpleton that’s no more interesting than a labrat, intellectually and emotionally speaking… well I sorta want you to be happy, but only as much as I want labrats to be happy.</p>
<p>If wireheading just makes you euphoric but still living a full life. Then yeah go ahead, why ever not.</p>
</blockquote>
<p>“&hellip;the complexity of life has to exist to be happy.”</p><p>This <i>seems</i> like an obvious thing to think, like a position sufficiently normal that you can just toss it off &ndash; that’s not a dig at you, it <i>seems</i> that way to me too, in a very visceral way &ndash; but in fact it’s a dodge.  It is the fundamental dodge that underlies all non-crazypants hedonic philosophies.  <br/></p><p>*****<br/></p><p>We have a strong instinct that happiness is a sort of warm emotional blanket that ought to cover life-in-general, that we ought to be basically happy most of the time unless something is <i>wrong</i>.  I don’t know whether that instinct is baked into the human psyche, or whether it arises from living in a modern civilized society where our basic needs are all easily met, or what.  There are enough conflicting arguments on that score to go around.  <br/></p><p>But from a brain-standpoint, from the standpoint of evo-psych, it is of course total nonsense.  Happiness is a mental prodding device, like pain and hunger and fear, that was “designed” to guide us through complex situations by activating in specific limited situations.  It’s the “ding!” that tells us that we did something right in a not-to-be-taken-for-granted way, and that we should try to do that thing again.  <br/></p><p>With resources and engineering skill, you can structure a life to maximize happiness, in the same way that you could structure a life to maximize hunger or fear or pain.  But it’s <i>not going to look very much like normal human existence</i>.  One way or another, it’s going to be totally built around exploits (in the cheating-at-video-games sense); it’s going to rely on superstimuli and brain glitches to keep normality at bay, because normality is the hedonic treadmill.  It’s going to be something very much like wireheading, even if it isn’t wireheading exactly.  It’s going to offend your aesthetic sensibilities, it’s going to look and feel <i>wrong</i>, because the lessons we learned about what looks <i>right </i>are all rooted in methods of existence that rely on happiness being a sometimes food.  <br/></p><p>*****</p><p>OK, having said all that: I am not at all convinced that I believe it.  But it’s certainly a <i>possibility</i>, in the least convenient of all possible worlds.  Building your system of ethics on a feature of the human brain means that you have to be prepared for neurology to work in a way that you wish it wouldn’t.</p><p>Or you can just define “happiness” in some wonky way that doesn’t basically map to a human brainstate.  That’s the standard move amongst mainstream utilitarian philosophers, as far as I can tell.  But it is what we call a <i>lie</i>, and leads to some truly unconvincing contortions as the philosophers in question try to hide the fact that they’re basically advocating for their own aesthetic preferences about life to be put into practice.  <br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/moral%20philosophy>#moral philosophy</a>
 — 25 notes — <a title=Source href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>bambamramfan</a></footer>
</article>

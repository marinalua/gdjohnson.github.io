<!DOCTYPE html>

<meta charset=utf-8>
<title>The Baliocene Apocrypha</title>
<link rel=stylesheet href=../backup.css>

<body class=archive>

<header>
<h1>January 2017</h1>
</header>

<article class=link id=p-156497201976>
<header>
<p><time datetime=2017-01-28T19:31:39Z>01/28/2017 02:31:39 PM</time>
<a class=llink href=../posts/156497201976.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HlzSiu>●</a>
</header>
<h2><a href="https://balioc.wordpress.com/2017/01/28/never-has-a-fantasy-been-more-final-part-1/">Never Has a Fantasy Been More Final, Part 1</a></h2>
<p>In the wake of my finishing the storyline of Final Fantasy XV: some thoughts about things that aren’t the reason that the series is good.<br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/real%20blog%20post>#real blog post</a>
 — 1 note</footer>
</article>
<article class=text id=p-156489318296>
<header>
<p><time datetime=2017-01-28T15:49:03Z>01/28/2017 10:49:03 AM</time>
<a class=llink href=../posts/156489318296.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HlVN_O>●</a>
<a href=https://raggedjackscarlet.tumblr.com/post/156474316818/was-anyone-else-honestly-disturbed-by-the>⬈</a>
</header>
<p><a href="http://raggedjackscarlet.tumblr.com/post/156474316818/was-anyone-else-honestly-disturbed-by-the" class="tumblr_blog">raggedjackscarlet</a>:</p><blockquote>
<p>was anyone else honestly disturbed by the<i> Passengers</i> discourse?</p>
<p>I just can’t fathom any human being with a scrap of empathy saying “well if you were a GOOD PERSON your response to a lifetime of solitary confinement would be to INSTANTLY become a HYPER-IDEALIZED FATHER FIGURE with ZERO EMOTIONAL NEEDS”<br/></p>
</blockquote>
<p>So I should start by noting: I haven’t actually seen <i>Passengers</i>, or encountered very much of the discourse to which you refer.  I know the basic plot concept from Internet spoilers, and I’ve seen seen a couple of cutesy Tumblr fanfics about the Chris Pratt character making some different choices.  But if there are relevant subtleties that can be drawn out of the text itself, or facets of the discourse that feature people being especially callous, I’m totally missing them.</p><p>That said &ndash; <br/></p><p>It sounds as though, if you read it along the grain, <i>Passengers </i>is not a moral-dilemma story so much as a <i>temptation</i> story.  And a very powerful one.  (Unusually so, given that these days we don’t have a lot of cultural energy invested in the concept of resisting temptation.)  <br/></p><p>“You are in a monstrous, terrible, mind-and-soul-destroying situation.  For reasons that are not your fault, you have been sentenced to lifelong solitary confinement.  Your only hope of ever knowing any human contact&hellip;is to condemn another innocent to your situation so that at least you can have a cellmate.  At best, this will be awful for her, a cruelty that she didn’t do anything to deserve &ndash; a life-with-two is better than a life-with-one, but it’s still not what anyone wants, it’s still the destruction of all her hopes and dreams and joys for the sake of your own sanity.  Will you inflict that on someone else?  How much will you suppress your own needs for the sake of others?”  <br/></p><p>There is clearly a correct answer here, a <i>heroic </i>answer, according to Normal-Person Conventional Morality.  Heroes are un-selfish enough that they’re willing to suffer harm to save others.  That’s pretty much the choice being presented here.  <br/></p><p>Given that, it’s unfair to call the Chris Pratt character a monster.  He may have failed his moral test, but it was an astonishingly difficult one, and there’s an awful lot of room between “hero” and “monster.”  <br/></p><p>It is also unfair to castigate people for fantasizing about the version of the story where he <i>is </i>that heroic, and manages to pull off his heroism with style and grace.  The Hyper-Idealized Father Figure version of the character is a totally legit moral exemplar, and I’m not opposed to people telling admiring stories about moral exemplars.  <br/></p><p>One way or another, it seems like a bad plan to insist that this Extreme Space Trolley Problem is a direct metaphor for real-life much-smaller-bore conflicts of personal interest.   <br/></p>
<footer>50 notes</footer>
</article>
<article class=link id=p-156387055356>
<header>
<p><time datetime=2017-01-26T05:27:15Z>01/26/2017 12:27:15 AM</time>
<a class=llink href=../posts/156387055356.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HfPHRy>●</a>
<a href=https://wirehead-wannabe.tumblr.com/post/156386717833/monero-the-drug-dealers-cryptocurrency-of>⬀</a>
<a href=https://voxette-vk.tumblr.com/post/156378643377/monero-the-drug-dealers-cryptocurrency-of>⬈</a>
</header>
<h2><a href="https://www.wired.com/2017/01/monero-drug-dealers-cryptocurrency-choice-fire#slide-3">Monero, the Drug Dealer’s Cryptocurrency of Choice, Is on Fire</a></h2>
<p><a href="http://wirehead-wannabe.tumblr.com/post/156386717833/monero-the-drug-dealers-cryptocurrency-of" class="tumblr_blog">wirehead-wannabe</a>:</p><blockquote>
<p><a href="http://voximperatoris.tumblr.com/post/156386668327/monero-the-drug-dealers-cryptocurrency-of" class="tumblr_blog">voximperatoris</a>:</p>

<blockquote>
<p><a href="http://wirehead-wannabe.tumblr.com/post/156386230138/monero-the-drug-dealers-cryptocurrency-of" class="tumblr_blog">wirehead-wannabe</a>:</p>

<blockquote>
<p><a href="http://voximperatoris.tumblr.com/post/156385947242/monero-the-drug-dealers-cryptocurrency-of" class="tumblr_blog">voximperatoris</a>:</p>

<blockquote>
<p><a href="http://ranma-official.tumblr.com/post/156385422825/monero-the-drug-dealers-cryptocurrency-of" class="tumblr_blog">ranma-official</a>:</p>

<blockquote>
<p><a href="http://wirehead-wannabe.tumblr.com/post/156379087483/monero-the-drug-dealers-cryptocurrency-of" class="tumblr_blog">wirehead-wannabe</a>:</p>

<blockquote><p>Has anyone come up with a general solution yet to the problem of turning cryptocurrency into something you can pay your landlord or grocer with? I haven’t looked much into it, but that always seemed like the most difficult step, especially if the government just decides to up and ban anyone from using cryptocurrency at all.</p></blockquote>

<p>It’s a solution looking for a problem at the moment. A number of businesses accept Bitcoin, but they solely do so out of novelty.</p>
<p>I can’t pay my electric bills with yen either. There must be an electric company that accepts yen, and that would be nice for Japanese visitors, but nonetheless.</p>
</blockquote>

<p>The idea is not to pay your landlord in Bitcoins, as in forcing him to hold or exchange them. Obviously, very few of them are going to want to do that.</p>
<p>But currently, any place that accepts credit/debit cards “accepts yen” because the conversion will be done automatically behind the scenes between the banks.</p>
<p>That’s how I bought a lot of stuff in Russia. Unless I was paying in cash, I didn’t need to convert my money to rubles beforehand, and the business didn’t need to be interested in holding dollars.</p>
</blockquote>

<p>I wonder how easy it would be to come up with a way of creating a secure, private cryptocurrency that just gives the government a small cut of each transaction. It sounds really hard, but if someone managed to do it then they would at least be fighting less of an uphill battle.</p>
</blockquote>

<p>It sounds really easy to me.</p>
<p>Bitcoin clients already include by default a small transaction fee that goes to the miners (though it’s not strictly necessary to include the fee).</p>
<p>You could easily create a client that would automatically send part of every transaction to a specific account controlled by the government. It wouldn’t make Bitcoin any less anonymous.</p>
<p>The problem would be convincing people to use it.</p>
</blockquote>

<p>I mean, if the government gets automatic sales tax on all transactions I’m sure the politicians would find a way to promote it</p>
</blockquote>
<p>&hellip;that is not actually how things work, at least if we’re talking about the US federal government, which does not very much resemble a business in terms of the way it operates.  The interests that motivate the decision-makers don’t look anything like “bring in money as easily as possible.”  <br/></p><p>Hell, I’m pretty sure that the current Congress would oppose such a technology on principle.  Republican legislators oppose <i>anything </i>that makes the process of tax-paying easier and smoother.  This is partly because Intuit (the TurboTax company) has a surprising amount of clout, but mostly because Republicans find it ideologically beneficial for taxes to be as stressful and annoying as possible.  <br/></p>
<footer>47 notes — <a title=Source href=https://voxette-vk.tumblr.com/post/156378643377/monero-the-drug-dealers-cryptocurrency-of>voxette-vk</a></footer>
</article>
<article class=text id=p-156368649686>
<header>
<p><time datetime=2017-01-25T21:14:00Z>01/25/2017 04:14:00 PM</time>
<a class=llink href=../posts/156368649686.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HeJ3tM>●</a>
<a href=https://bambamramfan.tumblr.com/post/156368209222/a-challenge-question-2>⬀</a>
<a href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>⬈</a>
</header>
<h2>A Challenge: Question 2</h2>
<p><a href="http://bambamramfan.tumblr.com/post/156368209222/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://balioc.tumblr.com/post/156367544996/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156364140162/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://balioc.tumblr.com/post/156358549336/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156313876367/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://balioc.tumblr.com/post/156313571146/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p>My favorite thing about the <a href="https://thingofthings.wordpress.com/2016/10/20/itt-social-justice-10/">ITT </a>is the way people answer question 2 “

What is the true reason, deep down, that you believe what you believe? What piece of evidence, test, or line of reasoning would convince you that you’re wrong about your ideology?”

</p>
<p>I’m certain every single respondent has thought deeply about what they believe. They’ve seen studies that back them up, thought about ethical principles, and seen the effects of oppression first hand. But when asked “why do you really believe this? what swayed you so much that it would change your mind if it was contradicted”… they often dissolve into vagueness and “everything shows I’m right!” Everything, of course, can never be disproven.</p>
<p>It’s a fascinating insight into how ideology works. Ideology isn’t formed by realizing our terminal values, or reading a study, it’s a much more osmotic experience than that. It involves quasi-believing things because so many other people we know believe them, and not questioning them *too* much because doing so is uncomfortable (both socially, and to our own identity as a good person.) Like <a href="https://srconstantin.wordpress.com/2016/10/20/ra/">Ra</a>, ideology hates it when you try to pin down terms and reasons too precisely.</p>
<p>So. Let’s do that. Here is my challenge to any rebloggers: <b>What is the true reason deep down that you believe what you believe? What evidence could convince you that you were wrong?</b></p>
<p>I’ll start.</p>
<hr><p>This tumblr is arguing the humanist viewpoint, so I’ll focus on why I’m a humanist, and what could sway me into other philosophies (specifically: parochial tribalism, anti-human universalism, or rights based liberalism and materialism.)</p>
<p>My terminal value is not special. It’s basically happy people, with an emphasis on complex and interesting lives and societies. My own personal goal is to find a button that increases human happiness no matter how much you push it, and to keep pushing it until it breaks.</p>
<p>It turns out that most of the things that we think increase human happiness, such as having better living conditions or more money, don’t really. And even our attempts to build up economies so that people have more stuff, are horribly complicated and unpredictable. I am distinctly unimpressed with a lot of the rationalist projects in this regard, and I suspect they will spend decades trying to find ways to improve the happiness of others with material interventions, and rarely feel they have made much success. There will still be misery everywhere, even after billions are spent. (If rationalist interventions started making a measurable and sizable impact in the amount of misery in the world, that would be evidence to change my view.) (Yes I saw <a href="http://slatestarcodex.com/2016/01/10/slow-but-steady/">Scott’s chart about malaria interventions</a>. I approve of malaria interventions. And the euphoria in the comments only emphasized to me how many rationalists are insecure about whether this project of theirs is having any results.)</p>
<p>Additionally, a lot of the rules we set down about how we should treat each other should increase human happiness, but mostly make humans miserable as they fight over the rules, and the rules are enforced haphazardly, with some receiving the extreme brunt of enforcement and others being afraid there isn’t enough enforcement. Which is why I am skeptical of rights based liberalism, and will continue to be until it is shown to be a better social technology than primitive tribalism.</p>
<p>The button that does work, that in my experience does make people reliably feel better, is listening to them and one-on-one interaction. Humans are social animals, and humans have very unique individual experiences. Respecting that individual complexity, and giving them social validation, seems the most reliably way to increase happiness, even if only on a very small scale.</p>
<p>If listening and validation are shown to be in the long run net-negative in happiness (if for instance, they operate like a drug that gives you a high that you then grow tolerant for) then I would be skeptical of that button.<br/>If there is no button that can reliably increase human happiness, well that would say a great deal about the chaotic nature of the human condition, which fundamentally validates my anti-categorical humanism.</p>
<p>But basically… if any button on the human psyche is shown to have reliable results - peer reviewed and consistently replicated - about how to affect people and make them happy, I would throw my philosophy out the window and pursue that. My current stance is a result of failure to find anything like that.</p>
<p>Now, humanism might just be speciesist, and it’s possible I don’t give enough credit to non-humans and dehumanized subjects. By appreciating complexity, I may be favoring people who’ve had interesting lives over people who have been so beaten down by the system that they will always be boring to me. This is a real risk and why I dabble in universalism elsewhere. But for now, my interactions with any human have shown that no matter how degraded they have been by society, they’re still as intelligent and social as the richest person I’ve met when you just listen to them for 10 minutes. If this were shown not to be the case statistically, I’d feel guilty about the inherent elitism of humanism, and I’d focus more on a philosophy that tries to exalt the most degraded and inhuman subjects.</p>
<p>Similarly for species, there seems a large gap in cognitive quality between humans and any other creature. If some species existed that were just somewhat less intelligent than humans but still identifiable as having a subjective experience in there, I’d have to look into a much more gradient focused definition of sentience and moral agency.<br/></p>
</blockquote>
<p><a class="tumblelog" href="https://tmblr.co/mz00oSVg_TogMX7aKjMrhQA">@jadagul</a> ‘s statement</p>
<blockquote><p>

I have a basically unshakeable conviction that people are mostly decent, and will treat most people well, and would like me to be happy. And following that belief has served me well.<br/>If I ever lost that belief, I would have to seriously rethink my ethics–my current position of trust-by-default would make a lot less sense, and I would probably find it much harder to sustain universal love and acceptance.

<br/></p></blockquote>
<p>from their (he? she? I don’t know) <a href="http://jadagul.tumblr.com/post/156300960938/bambamramfan-said-id-be-interested-in-your">post here</a>, reminded me of the above challenge. More people should do it!</p>
</blockquote>
<p>“But basically… if any button on the human psyche is shown to have 
reliable results - peer reviewed and consistently replicated - about how
 to affect people and make them happy, I would throw my philosophy out 
the window and pursue that. My current stance is a result of failure to 
find anything like that.”</p>
<p>…I think this means that you have to have an answer to “why not wireheading?”</p>
<p>Yeah, I know, it’s the most sophomoric of objections.  But wireheading <i>is </i>a thing, and it <i>does</i> reliably make people happy without them developing a tolerance.  The first-order problem with it for philosophers, in cynical terms, is that from the outside it creates something that looks less like our normal models of happiness than like drug addiction.  If you have non-hedonic terminal values, it’s very easy to explain why it’s not good enough.  But you seem to be working at a project where any conceivable result is going to look very weird from the standpoint of a normal person with normal assumptions.  So, uh, what’s wrong with the answer you’ve got?<br/></p>
</blockquote>
<p>I’d want to see the literature on existing wireheading technology as it is now. I’m not really aware of it, and how it works would matter a lot.</p>
<p>The perspective I mention is more to say “lots of people say their idea makes humanity better off, but then does not hold up under empirical verification on a consistent basis.” This is a frequent enough occurrence that it’s a good default stance towards a lot of social engineering and direct neurochemical futzing. Wearing the humanist mask, I find this fact existentially interesting.</p>
<p>Faced with the actual wireheading dilemma, I would probably say that the complexity of life has to exist to be happy. If wireheading makes you a simpleton that’s no more interesting than a labrat, intellectually and emotionally speaking… well I sorta want you to be happy, but only as much as I want labrats to be happy.</p>
<p>If wireheading just makes you euphoric but still living a full life. Then yeah go ahead, why ever not.</p>
</blockquote>
<p>“…the complexity of life has to exist to be happy.”</p>
<p>This <i>seems</i> like an obvious thing to think, like a position sufficiently normal that you can just toss it off – that’s not a dig at you, it <i>seems</i> that way to me too, in a very visceral way – but in fact it’s a dodge.  It is the fundamental dodge that underlies all non-crazypants hedonic philosophies.  <br/></p>
<p>*****<br/></p>
<p>We have a strong instinct that happiness is a sort of warm emotional blanket that ought to cover life-in-general, that we ought to be basically happy most of the time unless something is <i>wrong</i>.  I don’t know whether that instinct is baked into the human psyche, or whether it arises from living in a modern civilized society where our basic needs are all easily met, or what.  There are enough conflicting arguments on that score to go around.  <br/></p>
<p>But from a brain-standpoint, from the standpoint of evo-psych, it is of course total nonsense.  Happiness is a mental prodding device, like pain and hunger and fear, that was “designed” to guide us through complex situations by activating in specific limited situations.  It’s the “ding!” that tells us that we did something right in a not-to-be-taken-for-granted way, and that we should try to do that thing again.  <br/></p>
<p>With resources and engineering skill, you can structure a life to maximize happiness, in the same way that you could structure a life to maximize hunger or fear or pain.  But it’s <i>not going to look very much like normal human existence</i>.  One way or another, it’s going to be totally built around exploits (in the cheating-at-video-games sense); it’s going to rely on superstimuli and brain glitches to keep normality at bay, because normality is the hedonic treadmill.  It’s going to be something very much like wireheading, even if it isn’t wireheading exactly.  It’s going to offend your aesthetic sensibilities, it’s going to look and feel <i>wrong</i>, because the lessons we learned about what looks <i>right </i>are all rooted in methods of existence that rely on happiness being a sometimes food.  <br/></p>
<p>*****</p>
<p>OK, having said all that: I am not at all convinced that I believe it.  But it’s certainly a <i>possibility</i>, in the least convenient of all possible worlds.  Building your system of ethics on a feature of the human brain means that you have to be prepared for neurology to work in a way that you wish it wouldn’t.</p>
<p>Or you can just define “happiness” in some wonky way that doesn’t basically map to a human brainstate.  That’s the standard move amongst mainstream utilitarian philosophers, as far as I can tell.  But it is what we call a <i>lie</i>, and leads to some truly unconvincing contortions as the philosophers in question try to hide the fact that they’re basically advocating for their own aesthetic preferences about life to be put into practice.  <br/></p>
</blockquote>
<p>If I’m reading you right, you’re saying happiness is more like an optimization mechanism, than a stable state itself that you can be in or out of.</p>
<p>I agree. I probably misphrased myself originally. As an empirical matter, there seemed to be no easy way to “just keep people happy”. That is probably related to your explanation above.</p>
<p>But <i>I tried that first</i> (and read about people trying it a lot), and the conclusion seems to be that it is really incredibly hard no way more than “if my guy wins elections her policies will make this happiness happen”.</p>
</blockquote>
<p>I think I didn’t explain myself very clearly, for which I apologize.</p>
<p>The point of the wireheading example is: there <i>is </i>an easy way to “just keep people happy.”  All it takes is a little piece of metal, a generator, and some brain surgery.  We have everything we need to do it right now.  <br/></p>
<p>Of course, the result you get out of that methodology is icky.  It is not at all what you want!  (Probably.  You might be some kind of <a href="http://ethicalwerewolf.blogspot.com/">ethical werewolf</a> or something.  Or maybe you’ve done enough fiddling with the aesthetics that you can appreciate the <a href="http://slatestarcodex.com/2014/01/28/wirehead-gods-on-lotus-thrones/">gods on their lotus thrones</a>.)  <br/></p>
<p>This is not because wireheading gives you some kind of fake not-good-enough happiness.  This is because <i>happiness isn’t actually the thing you want</i>.  
As you come closer and closer to maximizing happiness, through any methodology at all, you’re going to converge 

on a result that will bother you in the same way that wireheading bothers you.  A sufficiently-reliable happiness engine will inevitably produce imbecile simplicity, because the dribs-and-drabs scarcity of happiness – and the consequent scramble to attain it – is one of the key factors in the kind of appealingly complicated life that you’ve learned to value. <br/></p>
<p>(Fictional evidence isn’t trustworthy, but for sheer conceptual punchiness on this exact topic as it addresses your interests, I think it’s useful to turn to David Foster Wallace.  <i>Infinite Jest </i>has, as its central Macguffin, something that is basically wireheading-in-video-tape-form: a short movie that produces addictive euphoria when watched.  And the content of that movie is <i>perfect infinitely-accessible emotional validation of the viewer</i>.)  <br/></p>
<p>There are lots of ways to address this problem, lots of alternate philosophical paths you can take.  But so long as you think you’re aiming to maximize a single value, you’re just going to push farther and farther into maximized-value territory until you suddenly discover the Monster at the End of the Book and freak out.<br/></p>
</blockquote>
<p>No i think I got you. (Is anyone else even following this argument anymore, besides <a class="tumblelog" href="https://tmblr.co/mWjGooV5hnjIdgTiG6Vy4tg">@cloakofshadow</a> ?)</p>
<p>If the wireheading just eventually leads you to being a blissed out lab rat, then I stand by my “complexity has diminished” caveat. It doesn’t really matter what got you there, what matters is at that point you are more like a thing that is dead than a human that is alive, and I’m only so glad you’re happy.</p>
<p>But to bite the bullet more, i think we are just using different measures of happiness. I want people to be not afraid, not anxious, and not in pain. I think that human oppression is caused not by greed, but by fear, and if you remove fear, people’s natural generosity and altruism makes them treat each other well.</p>
<p>If wireheading doesn’t have that effect because it doesn’t remove fear and anxiety, then it’s not the happiness my goal is based around.</p>
<p>If wireheading doesn’t have that effect because even without fear and anxiety we are still selfish dicks who oppress each other, then I have to substantially rethink my understanding of the world. As I said, I’d need to see current literature.</p>
<p>If wireheading <i>does</i> have that effect, then I am all in favor of it and sign me up now. I don’t want to be afraid and anxious anymore. </p>
<p>I don’t think that’s the case though.</p>
</blockquote>
<p>I mean&hellip;at the very least, it’s easy enough to posit a wireheading technology that has that effect.  <br/></p><p>(My <i>understanding </i>is that real-life wireheaders at our tech level, who generally are not just allowed to keep the machine on at the top setting until they die, are afraid and anxious of exactly one thing: that their access to the stimulus will be taken away.  But of course that’s usually not what people mean when they bring up the philosophical hypothetical.  And it’s not hard to rig the setup such that this is not a worry any more than starvation is a worry for us.)</p><p>And what do you have then?  You’re not anxious or afraid, because you’re a blissed-out lab rat.  Turns out that’s what not being anxious or afraid, in a serious sustainable way, gets you.  This is not a circle that can be squared.  The kind of human life to which you instinctively assign value runs on an engine of fear and pain.  <br/></p><p>*****</p><p><i>To reiterate: I am not actually convinced that this is true.  But I think it’s a real possibility that you have to take into account before you can commit to hedonic consequentialism in a principled way.</i><br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/moral%20philosophy>#moral philosophy</a>
 — 25 notes — <a title=Source href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>bambamramfan</a></footer>
</article>
<article class=text id=p-156367544996>
<header>
<p><time datetime=2017-01-25T20:45:25Z>01/25/2017 03:45:25 PM</time>
<a class=llink href=../posts/156367544996.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HeEsAa>●</a>
<a href=https://bambamramfan.tumblr.com/post/156364140162/a-challenge-question-2>⬀</a>
<a href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>⬈</a>
</header>
<h2>A Challenge: Question 2</h2>
<p><a href="http://bambamramfan.tumblr.com/post/156364140162/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://balioc.tumblr.com/post/156358549336/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156313876367/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://balioc.tumblr.com/post/156313571146/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p>My favorite thing about the <a href="https://thingofthings.wordpress.com/2016/10/20/itt-social-justice-10/">ITT </a>is the way people answer question 2 “

What is the true reason, deep down, that you believe what you believe? What piece of evidence, test, or line of reasoning would convince you that you’re wrong about your ideology?”

</p>
<p>I’m certain every single respondent has thought deeply about what they believe. They’ve seen studies that back them up, thought about ethical principles, and seen the effects of oppression first hand. But when asked “why do you really believe this? what swayed you so much that it would change your mind if it was contradicted”… they often dissolve into vagueness and “everything shows I’m right!” Everything, of course, can never be disproven.</p>
<p>It’s a fascinating insight into how ideology works. Ideology isn’t formed by realizing our terminal values, or reading a study, it’s a much more osmotic experience than that. It involves quasi-believing things because so many other people we know believe them, and not questioning them *too* much because doing so is uncomfortable (both socially, and to our own identity as a good person.) Like <a href="https://srconstantin.wordpress.com/2016/10/20/ra/">Ra</a>, ideology hates it when you try to pin down terms and reasons too precisely.</p>
<p>So. Let’s do that. Here is my challenge to any rebloggers: <b>What is the true reason deep down that you believe what you believe? What evidence could convince you that you were wrong?</b></p>
<p>I’ll start.</p>
<hr><p>This tumblr is arguing the humanist viewpoint, so I’ll focus on why I’m a humanist, and what could sway me into other philosophies (specifically: parochial tribalism, anti-human universalism, or rights based liberalism and materialism.)</p>
<p>My terminal value is not special. It’s basically happy people, with an emphasis on complex and interesting lives and societies. My own personal goal is to find a button that increases human happiness no matter how much you push it, and to keep pushing it until it breaks.</p>
<p>It turns out that most of the things that we think increase human happiness, such as having better living conditions or more money, don’t really. And even our attempts to build up economies so that people have more stuff, are horribly complicated and unpredictable. I am distinctly unimpressed with a lot of the rationalist projects in this regard, and I suspect they will spend decades trying to find ways to improve the happiness of others with material interventions, and rarely feel they have made much success. There will still be misery everywhere, even after billions are spent. (If rationalist interventions started making a measurable and sizable impact in the amount of misery in the world, that would be evidence to change my view.) (Yes I saw <a href="http://slatestarcodex.com/2016/01/10/slow-but-steady/">Scott’s chart about malaria interventions</a>. I approve of malaria interventions. And the euphoria in the comments only emphasized to me how many rationalists are insecure about whether this project of theirs is having any results.)</p>
<p>Additionally, a lot of the rules we set down about how we should treat each other should increase human happiness, but mostly make humans miserable as they fight over the rules, and the rules are enforced haphazardly, with some receiving the extreme brunt of enforcement and others being afraid there isn’t enough enforcement. Which is why I am skeptical of rights based liberalism, and will continue to be until it is shown to be a better social technology than primitive tribalism.</p>
<p>The button that does work, that in my experience does make people reliably feel better, is listening to them and one-on-one interaction. Humans are social animals, and humans have very unique individual experiences. Respecting that individual complexity, and giving them social validation, seems the most reliably way to increase happiness, even if only on a very small scale.</p>
<p>If listening and validation are shown to be in the long run net-negative in happiness (if for instance, they operate like a drug that gives you a high that you then grow tolerant for) then I would be skeptical of that button.<br/>If there is no button that can reliably increase human happiness, well that would say a great deal about the chaotic nature of the human condition, which fundamentally validates my anti-categorical humanism.</p>
<p>But basically… if any button on the human psyche is shown to have reliable results - peer reviewed and consistently replicated - about how to affect people and make them happy, I would throw my philosophy out the window and pursue that. My current stance is a result of failure to find anything like that.</p>
<p>Now, humanism might just be speciesist, and it’s possible I don’t give enough credit to non-humans and dehumanized subjects. By appreciating complexity, I may be favoring people who’ve had interesting lives over people who have been so beaten down by the system that they will always be boring to me. This is a real risk and why I dabble in universalism elsewhere. But for now, my interactions with any human have shown that no matter how degraded they have been by society, they’re still as intelligent and social as the richest person I’ve met when you just listen to them for 10 minutes. If this were shown not to be the case statistically, I’d feel guilty about the inherent elitism of humanism, and I’d focus more on a philosophy that tries to exalt the most degraded and inhuman subjects.</p>
<p>Similarly for species, there seems a large gap in cognitive quality between humans and any other creature. If some species existed that were just somewhat less intelligent than humans but still identifiable as having a subjective experience in there, I’d have to look into a much more gradient focused definition of sentience and moral agency.<br/></p>
</blockquote>
<p><a class="tumblelog" href="https://tmblr.co/mz00oSVg_TogMX7aKjMrhQA">@jadagul</a> ‘s statement</p>
<blockquote><p>

I have a basically unshakeable conviction that people are mostly decent, and will treat most people well, and would like me to be happy. And following that belief has served me well.<br/>If I ever lost that belief, I would have to seriously rethink my ethics–my current position of trust-by-default would make a lot less sense, and I would probably find it much harder to sustain universal love and acceptance.

<br/></p></blockquote>
<p>from their (he? she? I don’t know) <a href="http://jadagul.tumblr.com/post/156300960938/bambamramfan-said-id-be-interested-in-your">post here</a>, reminded me of the above challenge. More people should do it!</p>
</blockquote>
<p>“But basically… if any button on the human psyche is shown to have 
reliable results - peer reviewed and consistently replicated - about how
 to affect people and make them happy, I would throw my philosophy out 
the window and pursue that. My current stance is a result of failure to 
find anything like that.”</p>
<p>…I think this means that you have to have an answer to “why not wireheading?”</p>
<p>Yeah, I know, it’s the most sophomoric of objections.  But wireheading <i>is </i>a thing, and it <i>does</i> reliably make people happy without them developing a tolerance.  The first-order problem with it for philosophers, in cynical terms, is that from the outside it creates something that looks less like our normal models of happiness than like drug addiction.  If you have non-hedonic terminal values, it’s very easy to explain why it’s not good enough.  But you seem to be working at a project where any conceivable result is going to look very weird from the standpoint of a normal person with normal assumptions.  So, uh, what’s wrong with the answer you’ve got?<br/></p>
</blockquote>
<p>I’d want to see the literature on existing wireheading technology as it is now. I’m not really aware of it, and how it works would matter a lot.</p>
<p>The perspective I mention is more to say “lots of people say their idea makes humanity better off, but then does not hold up under empirical verification on a consistent basis.” This is a frequent enough occurrence that it’s a good default stance towards a lot of social engineering and direct neurochemical futzing. Wearing the humanist mask, I find this fact existentially interesting.</p>
<p>Faced with the actual wireheading dilemma, I would probably say that the complexity of life has to exist to be happy. If wireheading makes you a simpleton that’s no more interesting than a labrat, intellectually and emotionally speaking… well I sorta want you to be happy, but only as much as I want labrats to be happy.</p>
<p>If wireheading just makes you euphoric but still living a full life. Then yeah go ahead, why ever not.</p>
</blockquote>
<p>“…the complexity of life has to exist to be happy.”</p>
<p>This <i>seems</i> like an obvious thing to think, like a position sufficiently normal that you can just toss it off – that’s not a dig at you, it <i>seems</i> that way to me too, in a very visceral way – but in fact it’s a dodge.  It is the fundamental dodge that underlies all non-crazypants hedonic philosophies.  <br/></p>
<p>*****<br/></p>
<p>We have a strong instinct that happiness is a sort of warm emotional blanket that ought to cover life-in-general, that we ought to be basically happy most of the time unless something is <i>wrong</i>.  I don’t know whether that instinct is baked into the human psyche, or whether it arises from living in a modern civilized society where our basic needs are all easily met, or what.  There are enough conflicting arguments on that score to go around.  <br/></p>
<p>But from a brain-standpoint, from the standpoint of evo-psych, it is of course total nonsense.  Happiness is a mental prodding device, like pain and hunger and fear, that was “designed” to guide us through complex situations by activating in specific limited situations.  It’s the “ding!” that tells us that we did something right in a not-to-be-taken-for-granted way, and that we should try to do that thing again.  <br/></p>
<p>With resources and engineering skill, you can structure a life to maximize happiness, in the same way that you could structure a life to maximize hunger or fear or pain.  But it’s <i>not going to look very much like normal human existence</i>.  One way or another, it’s going to be totally built around exploits (in the cheating-at-video-games sense); it’s going to rely on superstimuli and brain glitches to keep normality at bay, because normality is the hedonic treadmill.  It’s going to be something very much like wireheading, even if it isn’t wireheading exactly.  It’s going to offend your aesthetic sensibilities, it’s going to look and feel <i>wrong</i>, because the lessons we learned about what looks <i>right </i>are all rooted in methods of existence that rely on happiness being a sometimes food.  <br/></p>
<p>*****</p>
<p>OK, having said all that: I am not at all convinced that I believe it.  But it’s certainly a <i>possibility</i>, in the least convenient of all possible worlds.  Building your system of ethics on a feature of the human brain means that you have to be prepared for neurology to work in a way that you wish it wouldn’t.</p>
<p>Or you can just define “happiness” in some wonky way that doesn’t basically map to a human brainstate.  That’s the standard move amongst mainstream utilitarian philosophers, as far as I can tell.  But it is what we call a <i>lie</i>, and leads to some truly unconvincing contortions as the philosophers in question try to hide the fact that they’re basically advocating for their own aesthetic preferences about life to be put into practice.  <br/></p>
</blockquote>
<p>If I’m reading you right, you’re saying happiness is more like an optimization mechanism, than a stable state itself that you can be in or out of.</p>
<p>I agree. I probably misphrased myself originally. As an empirical matter, there seemed to be no easy way to “just keep people happy”. That is probably related to your explanation above.</p>
<p>But <i>I tried that first</i> (and read about people trying it a lot), and the conclusion seems to be that it is really incredibly hard no way more than “if my guy wins elections her policies will make this happiness happen”.</p>
</blockquote>
<p>I think I didn’t explain myself very clearly, for which I apologize.</p><p>The point of the wireheading example is: there <i>is </i>an easy way to “just keep people happy.”  All it takes is a little piece of metal, a generator, and some brain surgery.  We have everything we need to do it right now.  <br/></p><p>Of course, the result you get out of that methodology is icky.  It is not at all what you want!  (Probably.  You might be some kind of <a href="http://ethicalwerewolf.blogspot.com/">ethical werewolf</a> or something.  Or maybe you’ve done enough fiddling with the aesthetics that you can appreciate the <a href="http://slatestarcodex.com/2014/01/28/wirehead-gods-on-lotus-thrones/">gods on their lotus thrones</a>.)  <br/></p><p>This is not because wireheading gives you some kind of fake not-good-enough happiness.  This is because <i>happiness isn’t actually the thing you want</i>.  
As you come closer and closer to maximizing happiness, through any methodology at all, you’re going to converge 

on a result that will bother you in the same way that wireheading bothers you.  A sufficiently-reliable happiness engine will inevitably produce imbecile simplicity, because the dribs-and-drabs scarcity of happiness &ndash; and the consequent scramble to attain it &ndash; is one of the key factors in the kind of appealingly complicated life that you’ve learned to value. <br/></p><p>(Fictional evidence isn’t trustworthy, but for sheer conceptual punchiness on this exact topic as it addresses your interests, I think it’s useful to turn to David Foster Wallace.  <i>Infinite Jest </i>has, as its central Macguffin, something that is basically wireheading-in-video-tape-form: a short movie that produces addictive euphoria when watched.  And the content of that movie is <i>perfect infinitely-accessible emotional validation of the viewer</i>.)  <br/></p><p>There are lots of ways to address this problem, lots of alternate philosophical paths you can take.  But so long as you think you’re aiming to maximize a single value, you’re just going to push farther and farther into maximized-value territory until you suddenly discover the Monster at the End of the Book and freak out.<br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/moral%20philosophy>#moral philosophy</a>
 — 25 notes — <a title=Source href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>bambamramfan</a></footer>
</article>
<article class=text id=p-156358549336>
<header>
<p><time datetime=2017-01-25T16:18:33Z>01/25/2017 11:18:33 AM</time>
<a class=llink href=../posts/156358549336.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HdiXzO>●</a>
<a href=https://bambamramfan.tumblr.com/post/156313876367/a-challenge-question-2>⬀</a>
<a href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>⬈</a>
</header>
<h2>A Challenge: Question 2</h2>
<p><a href="http://bambamramfan.tumblr.com/post/156313876367/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://balioc.tumblr.com/post/156313571146/a-challenge-question-2" class="tumblr_blog">balioc</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p>My favorite thing about the <a href="https://thingofthings.wordpress.com/2016/10/20/itt-social-justice-10/">ITT </a>is the way people answer question 2 “

What is the true reason, deep down, that you believe what you believe? What piece of evidence, test, or line of reasoning would convince you that you’re wrong about your ideology?”

</p>
<p>I’m certain every single respondent has thought deeply about what they believe. They’ve seen studies that back them up, thought about ethical principles, and seen the effects of oppression first hand. But when asked “why do you really believe this? what swayed you so much that it would change your mind if it was contradicted”… they often dissolve into vagueness and “everything shows I’m right!” Everything, of course, can never be disproven.</p>
<p>It’s a fascinating insight into how ideology works. Ideology isn’t formed by realizing our terminal values, or reading a study, it’s a much more osmotic experience than that. It involves quasi-believing things because so many other people we know believe them, and not questioning them *too* much because doing so is uncomfortable (both socially, and to our own identity as a good person.) Like <a href="https://srconstantin.wordpress.com/2016/10/20/ra/">Ra</a>, ideology hates it when you try to pin down terms and reasons too precisely.</p>
<p>So. Let’s do that. Here is my challenge to any rebloggers: <b>What is the true reason deep down that you believe what you believe? What evidence could convince you that you were wrong?</b></p>
<p>I’ll start.</p>
<hr><p>This tumblr is arguing the humanist viewpoint, so I’ll focus on why I’m a humanist, and what could sway me into other philosophies (specifically: parochial tribalism, anti-human universalism, or rights based liberalism and materialism.)</p>
<p>My terminal value is not special. It’s basically happy people, with an emphasis on complex and interesting lives and societies. My own personal goal is to find a button that increases human happiness no matter how much you push it, and to keep pushing it until it breaks.</p>
<p>It turns out that most of the things that we think increase human happiness, such as having better living conditions or more money, don’t really. And even our attempts to build up economies so that people have more stuff, are horribly complicated and unpredictable. I am distinctly unimpressed with a lot of the rationalist projects in this regard, and I suspect they will spend decades trying to find ways to improve the happiness of others with material interventions, and rarely feel they have made much success. There will still be misery everywhere, even after billions are spent. (If rationalist interventions started making a measurable and sizable impact in the amount of misery in the world, that would be evidence to change my view.) (Yes I saw <a href="http://slatestarcodex.com/2016/01/10/slow-but-steady/">Scott’s chart about malaria interventions</a>. I approve of malaria interventions. And the euphoria in the comments only emphasized to me how many rationalists are insecure about whether this project of theirs is having any results.)</p>
<p>Additionally, a lot of the rules we set down about how we should treat each other should increase human happiness, but mostly make humans miserable as they fight over the rules, and the rules are enforced haphazardly, with some receiving the extreme brunt of enforcement and others being afraid there isn’t enough enforcement. Which is why I am skeptical of rights based liberalism, and will continue to be until it is shown to be a better social technology than primitive tribalism.</p>
<p>The button that does work, that in my experience does make people reliably feel better, is listening to them and one-on-one interaction. Humans are social animals, and humans have very unique individual experiences. Respecting that individual complexity, and giving them social validation, seems the most reliably way to increase happiness, even if only on a very small scale.</p>
<p>If listening and validation are shown to be in the long run net-negative in happiness (if for instance, they operate like a drug that gives you a high that you then grow tolerant for) then I would be skeptical of that button.<br/>If there is no button that can reliably increase human happiness, well that would say a great deal about the chaotic nature of the human condition, which fundamentally validates my anti-categorical humanism.</p>
<p>But basically… if any button on the human psyche is shown to have reliable results - peer reviewed and consistently replicated - about how to affect people and make them happy, I would throw my philosophy out the window and pursue that. My current stance is a result of failure to find anything like that.</p>
<p>Now, humanism might just be speciesist, and it’s possible I don’t give enough credit to non-humans and dehumanized subjects. By appreciating complexity, I may be favoring people who’ve had interesting lives over people who have been so beaten down by the system that they will always be boring to me. This is a real risk and why I dabble in universalism elsewhere. But for now, my interactions with any human have shown that no matter how degraded they have been by society, they’re still as intelligent and social as the richest person I’ve met when you just listen to them for 10 minutes. If this were shown not to be the case statistically, I’d feel guilty about the inherent elitism of humanism, and I’d focus more on a philosophy that tries to exalt the most degraded and inhuman subjects.</p>
<p>Similarly for species, there seems a large gap in cognitive quality between humans and any other creature. If some species existed that were just somewhat less intelligent than humans but still identifiable as having a subjective experience in there, I’d have to look into a much more gradient focused definition of sentience and moral agency.<br/></p>
</blockquote>
<p><a class="tumblelog" href="https://tmblr.co/mz00oSVg_TogMX7aKjMrhQA">@jadagul</a> ‘s statement</p>
<blockquote><p>

I have a basically unshakeable conviction that people are mostly decent, and will treat most people well, and would like me to be happy. And following that belief has served me well.<br/>If I ever lost that belief, I would have to seriously rethink my ethics–my current position of trust-by-default would make a lot less sense, and I would probably find it much harder to sustain universal love and acceptance.

<br/></p></blockquote>
<p>from their (he? she? I don’t know) <a href="http://jadagul.tumblr.com/post/156300960938/bambamramfan-said-id-be-interested-in-your">post here</a>, reminded me of the above challenge. More people should do it!</p>
</blockquote>
<p>“But basically… if any button on the human psyche is shown to have 
reliable results - peer reviewed and consistently replicated - about how
 to affect people and make them happy, I would throw my philosophy out 
the window and pursue that. My current stance is a result of failure to 
find anything like that.”</p>
<p>…I think this means that you have to have an answer to “why not wireheading?”</p>
<p>Yeah, I know, it’s the most sophomoric of objections.  But wireheading <i>is </i>a thing, and it <i>does</i> reliably make people happy without them developing a tolerance.  The first-order problem with it for philosophers, in cynical terms, is that from the outside it creates something that looks less like our normal models of happiness than like drug addiction.  If you have non-hedonic terminal values, it’s very easy to explain why it’s not good enough.  But you seem to be working at a project where any conceivable result is going to look very weird from the standpoint of a normal person with normal assumptions.  So, uh, what’s wrong with the answer you’ve got?<br/></p>
</blockquote>
<p>I’d want to see the literature on existing wireheading technology as it is now. I’m not really aware of it, and how it works would matter a lot.</p>
<p>The perspective I mention is more to say “lots of people say their idea makes humanity better off, but then does not hold up under empirical verification on a consistent basis.” This is a frequent enough occurrence that it’s a good default stance towards a lot of social engineering and direct neurochemical futzing. Wearing the humanist mask, I find this fact existentially interesting.</p>
<p>Faced with the actual wireheading dilemma, I would probably say that the complexity of life has to exist to be happy. If wireheading makes you a simpleton that’s no more interesting than a labrat, intellectually and emotionally speaking… well I sorta want you to be happy, but only as much as I want labrats to be happy.</p>
<p>If wireheading just makes you euphoric but still living a full life. Then yeah go ahead, why ever not.</p>
</blockquote>
<p>“&hellip;the complexity of life has to exist to be happy.”</p><p>This <i>seems</i> like an obvious thing to think, like a position sufficiently normal that you can just toss it off &ndash; that’s not a dig at you, it <i>seems</i> that way to me too, in a very visceral way &ndash; but in fact it’s a dodge.  It is the fundamental dodge that underlies all non-crazypants hedonic philosophies.  <br/></p><p>*****<br/></p><p>We have a strong instinct that happiness is a sort of warm emotional blanket that ought to cover life-in-general, that we ought to be basically happy most of the time unless something is <i>wrong</i>.  I don’t know whether that instinct is baked into the human psyche, or whether it arises from living in a modern civilized society where our basic needs are all easily met, or what.  There are enough conflicting arguments on that score to go around.  <br/></p><p>But from a brain-standpoint, from the standpoint of evo-psych, it is of course total nonsense.  Happiness is a mental prodding device, like pain and hunger and fear, that was “designed” to guide us through complex situations by activating in specific limited situations.  It’s the “ding!” that tells us that we did something right in a not-to-be-taken-for-granted way, and that we should try to do that thing again.  <br/></p><p>With resources and engineering skill, you can structure a life to maximize happiness, in the same way that you could structure a life to maximize hunger or fear or pain.  But it’s <i>not going to look very much like normal human existence</i>.  One way or another, it’s going to be totally built around exploits (in the cheating-at-video-games sense); it’s going to rely on superstimuli and brain glitches to keep normality at bay, because normality is the hedonic treadmill.  It’s going to be something very much like wireheading, even if it isn’t wireheading exactly.  It’s going to offend your aesthetic sensibilities, it’s going to look and feel <i>wrong</i>, because the lessons we learned about what looks <i>right </i>are all rooted in methods of existence that rely on happiness being a sometimes food.  <br/></p><p>*****</p><p>OK, having said all that: I am not at all convinced that I believe it.  But it’s certainly a <i>possibility</i>, in the least convenient of all possible worlds.  Building your system of ethics on a feature of the human brain means that you have to be prepared for neurology to work in a way that you wish it wouldn’t.</p><p>Or you can just define “happiness” in some wonky way that doesn’t basically map to a human brainstate.  That’s the standard move amongst mainstream utilitarian philosophers, as far as I can tell.  But it is what we call a <i>lie</i>, and leads to some truly unconvincing contortions as the philosophers in question try to hide the fact that they’re basically advocating for their own aesthetic preferences about life to be put into practice.  <br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/moral%20philosophy>#moral philosophy</a>
 — 25 notes — <a title=Source href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>bambamramfan</a></footer>
</article>
<article class=text id=p-156313571146>
<header>
<p><time datetime=2017-01-24T16:03:59Z>01/24/2017 11:03:59 AM</time>
<a class=llink href=../posts/156313571146.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2Hb0yzA>●</a>
<a href=https://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2>⬀</a>
<a href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>⬈</a>
</header>
<h2>A Challenge: Question 2</h2>
<p><a href="http://bambamramfan.tumblr.com/post/156313000282/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2" class="tumblr_blog">bambamramfan</a>:</p>
<blockquote>
<p>My favorite thing about the <a href="https://thingofthings.wordpress.com/2016/10/20/itt-social-justice-10/">ITT </a>is the way people answer question 2 “

What is the true reason, deep down, that you believe what you believe? What piece of evidence, test, or line of reasoning would convince you that you’re wrong about your ideology?”

</p>
<p>I’m certain every single respondent has thought deeply about what they believe. They’ve seen studies that back them up, thought about ethical principles, and seen the effects of oppression first hand. But when asked “why do you really believe this? what swayed you so much that it would change your mind if it was contradicted”… they often dissolve into vagueness and “everything shows I’m right!” Everything, of course, can never be disproven.</p>
<p>It’s a fascinating insight into how ideology works. Ideology isn’t formed by realizing our terminal values, or reading a study, it’s a much more osmotic experience than that. It involves quasi-believing things because so many other people we know believe them, and not questioning them *too* much because doing so is uncomfortable (both socially, and to our own identity as a good person.) Like <a href="https://srconstantin.wordpress.com/2016/10/20/ra/">Ra</a>, ideology hates it when you try to pin down terms and reasons too precisely.</p>
<p>So. Let’s do that. Here is my challenge to any rebloggers: <b>What is the true reason deep down that you believe what you believe? What evidence could convince you that you were wrong?</b></p>
<p>I’ll start.</p>
<hr><p>This tumblr is arguing the humanist viewpoint, so I’ll focus on why I’m a humanist, and what could sway me into other philosophies (specifically: parochial tribalism, anti-human universalism, or rights based liberalism and materialism.)</p>
<p>My terminal value is not special. It’s basically happy people, with an emphasis on complex and interesting lives and societies. My own personal goal is to find a button that increases human happiness no matter how much you push it, and to keep pushing it until it breaks.</p>
<p>It turns out that most of the things that we think increase human happiness, such as having better living conditions or more money, don’t really. And even our attempts to build up economies so that people have more stuff, are horribly complicated and unpredictable. I am distinctly unimpressed with a lot of the rationalist projects in this regard, and I suspect they will spend decades trying to find ways to improve the happiness of others with material interventions, and rarely feel they have made much success. There will still be misery everywhere, even after billions are spent. (If rationalist interventions started making a measurable and sizable impact in the amount of misery in the world, that would be evidence to change my view.) (Yes I saw <a href="http://slatestarcodex.com/2016/01/10/slow-but-steady/">Scott’s chart about malaria interventions</a>. I approve of malaria interventions. And the euphoria in the comments only emphasized to me how many rationalists are insecure about whether this project of theirs is having any results.)</p>
<p>Additionally, a lot of the rules we set down about how we should treat each other should increase human happiness, but mostly make humans miserable as they fight over the rules, and the rules are enforced haphazardly, with some receiving the extreme brunt of enforcement and others being afraid there isn’t enough enforcement. Which is why I am skeptical of rights based liberalism, and will continue to be until it is shown to be a better social technology than primitive tribalism.</p>
<p>The button that does work, that in my experience does make people reliably feel better, is listening to them and one-on-one interaction. Humans are social animals, and humans have very unique individual experiences. Respecting that individual complexity, and giving them social validation, seems the most reliably way to increase happiness, even if only on a very small scale.</p>
<p>If listening and validation are shown to be in the long run net-negative in happiness (if for instance, they operate like a drug that gives you a high that you then grow tolerant for) then I would be skeptical of that button.<br/>If there is no button that can reliably increase human happiness, well that would say a great deal about the chaotic nature of the human condition, which fundamentally validates my anti-categorical humanism.</p>
<p>But basically… if any button on the human psyche is shown to have reliable results - peer reviewed and consistently replicated - about how to affect people and make them happy, I would throw my philosophy out the window and pursue that. My current stance is a result of failure to find anything like that.</p>
<p>Now, humanism might just be speciesist, and it’s possible I don’t give enough credit to non-humans and dehumanized subjects. By appreciating complexity, I may be favoring people who’ve had interesting lives over people who have been so beaten down by the system that they will always be boring to me. This is a real risk and why I dabble in universalism elsewhere. But for now, my interactions with any human have shown that no matter how degraded they have been by society, they’re still as intelligent and social as the richest person I’ve met when you just listen to them for 10 minutes. If this were shown not to be the case statistically, I’d feel guilty about the inherent elitism of humanism, and I’d focus more on a philosophy that tries to exalt the most degraded and inhuman subjects.</p>
<p>Similarly for species, there seems a large gap in cognitive quality between humans and any other creature. If some species existed that were just somewhat less intelligent than humans but still identifiable as having a subjective experience in there, I’d have to look into a much more gradient focused definition of sentience and moral agency.<br/></p>
</blockquote>
<p><a class="tumblelog" href="https://tmblr.co/mz00oSVg_TogMX7aKjMrhQA">@jadagul</a> ‘s statement</p>
<blockquote><p>

I have a basically unshakeable conviction that people are mostly decent, and will treat most people well, and would like me to be happy. And following that belief has served me well.<br/>If I ever lost that belief, I would have to seriously rethink my ethics–my current position of trust-by-default would make a lot less sense, and I would probably find it much harder to sustain universal love and acceptance.

<br/></p></blockquote>
<p>from their (he? she? I don’t know) <a href="http://jadagul.tumblr.com/post/156300960938/bambamramfan-said-id-be-interested-in-your">post here</a>, reminded me of the above challenge. More people should do it!</p>
</blockquote>
<p>“But basically… if any button on the human psyche is shown to have 
reliable results - peer reviewed and consistently replicated - about how
 to affect people and make them happy, I would throw my philosophy out 
the window and pursue that. My current stance is a result of failure to 
find anything like that.”</p><p>&hellip;I think this means that you have to have an answer to “why not wireheading?”</p><p>Yeah, I know, it’s the most sophomoric of objections.  But wireheading <i>is </i>a thing, and it <i>does</i> reliably make people happy without them developing a tolerance.  The first-order problem with it for philosophers, in cynical terms, is that from the outside it creates something that looks less like our normal models of happiness than like drug addiction.  If you have non-hedonic terminal values, it’s very easy to explain why it’s not good enough.  But you seem to be working at a project where any conceivable result is going to look very weird from the standpoint of a normal person with normal assumptions.  So, uh, what’s wrong with the answer you’ve got?<br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/moral%20philosophy>#moral philosophy</a>
 — 25 notes — <a title=Source href=https://bambamramfan.tumblr.com/post/152116448847/a-challenge-question-2>bambamramfan</a></footer>
</article>
<article class=link id=p-156313267181>
<header>
<p><time datetime=2017-01-24T15:54:19Z>01/24/2017 10:54:19 AM</time>
<a class=llink href=../posts/156313267181.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2Ha-olj>●</a>
<a href=https://bambamramfan.tumblr.com/post/156312576327/what-makes-things-good>⬀</a>
<a href=https://balioc.tumblr.com/post/156280023721/what-makes-things-good>⬈</a>
</header>
<h2><a href="https://balioc.wordpress.com/2017/01/23/what-makes-things-good/">What Makes Things Good</a></h2>
<p><a href="http://bambamramfan.tumblr.com/post/156312576327/what-makes-things-good" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<p><a href="http://balioc.tumblr.com/post/156280023721/what-makes-things-good" class="tumblr_blog">balioc</a>:</p>
<blockquote><p>A brief attempt to carve up the different kinds of value that art can provide.<br/></p></blockquote>
<p>These seem to make sense, but the role of subjectivity confuses the matter.</p>
<p>Stickiness is probably an objective trait of the work.</p>
<p>Literary merit should be something more than subjective, if we are saying it has positive value after all.</p>
<p>But why the hell is digestibility so damn subjective? The way you phrase it (which is quite reasonable) sounds like something that would be roughly similar across readers. But it isn’t, and this seems the trait that I am most uncertain whether another read will judge a book in the same way I do.</p>
</blockquote>
<p>Hrm.  I don’t actually think that digestibility <i>is </i>subjective, or at least not very much so.  It’s possible that we’re having an actual empirical disagreement, but it’s also possible that we’re just looking at different things.  So it’s worth teasing out a bit.</p><p>On a trivial level, obviously, <i>something </i>about the experience of media-consumption is very subjective.  Person A likes the movie, Person B hates it, this is the most common thing in the world.  My instinct is to say that it usually happens because of things that don’t really fit into the schema of “artistic virtue” at all.</p><p>The most obvious culprit is <i>content</i>.  If you really dislike the tense feeling of being fake-scared, you’re not going to enjoy a horror movie.  If your cultural training has taught you that spaceships and wizards are Dumb Stuff For Philistine Babies, you’re not going to enjoy a F/SF novel.  (For that matter, if your cultural training has taught you that spaceships and wizards are <i>required </i>for entertaining reading, you’re not going to enjoy Philip Roth talking about suburban Jewish angst in the ‘40s.)  If twitchy shooting and perception-management gameplay is confusing and un-fun for you, as it is for me, you’re not going to enjoy a first-person shooter.  <br/></p><p>But this is not a matter of virtue.  It’s not like you get Entertainment Points for having the “right” kind of content (which I guess would be the most popular kind?).  It seems obvious to me that horror movies can be good, that books can be good with OR without the genre trappings of F/SF, that first-person shooters can be good.   <br/></p><p>I posit that you can strip away all the content &ndash; the actual meat of the characters, the genre markers, the things that the audience <i>sees</i> and <i>cares about</i> &ndash; and be left with, essentially, the skeleton of an experience.  And that skeleton can be manipulated and reshaped, more or less successfully depending on your skill, so as to “digestible” in a way that is almost objective.  <br/></p><p>This is mostly going to be a matter of using the sort of tricks-of-the-trade that the analysts of TV and movies love to to talk about (presumably because TV and movies have been ruthlessly optimized for this in a way that most art forms haven’t).  Beats.  Act structure.  Cliffhangers.  Making sure that your audience is laughing and crying and feeling suspense at exactly the right moments so that boredom and irritation don’t set in.  <br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/literary%20theory>#literary theory</a>
 — 4 notes — <a title=Source href=https://balioc.tumblr.com/post/156280023721/what-makes-things-good>balioc</a></footer>
</article>
<article class=link id=p-156280023721>
<header>
<p><time datetime=2017-01-23T21:48:19Z>01/23/2017 04:48:19 PM</time>
<a class=llink href=../posts/156280023721.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HZ0_gf>●</a>
</header>
<h2><a href="https://balioc.wordpress.com/2017/01/23/what-makes-things-good/">What Makes Things Good</a></h2>
<p>A brief attempt to carve up the different kinds of value that art can provide.<br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/art>#art</a>
<a href=http://balioc.tumblr.com/tagged/real%20blog%20post>#real blog post</a>
 — 4 notes</footer>
</article>
<article class=text id=p-156269102366>
<header>
<p><time datetime=2017-01-23T16:50:11Z>01/23/2017 11:50:11 AM</time>
<a class=llink href=../posts/156269102366.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2HYNKKU>●</a>
<a href=https://brazenautomaton.tumblr.com/post/156266198224/dagothcares-chroniclesofrettek>⬀</a>
<a href=https://dog-of-ulthar.tumblr.com/post/156201449210/trump-is-an-awful-person-but-he-isnt-a-competent>⬈</a>
</header>
<p><a href="http://brazenautomaton.tumblr.com/post/156266198224/dagothcares-chroniclesofrettek" class="tumblr_blog">brazenautomaton</a>:</p>
<blockquote>
<p><a href="http://dagothcares.tumblr.com/post/156260227346/chroniclesofrettek-dog-of-ulthar-trump-is-an" class="tumblr_blog">dagothcares</a>:</p>
<blockquote>
<p><a href="http://chroniclesofrettek.tumblr.com/post/156254946707/dog-of-ulthar-trump-is-an-awful-person-but-he" class="tumblr_blog">chroniclesofrettek</a>:</p>
<blockquote>
<p><a href="http://dog-of-ulthar.tumblr.com/post/156201449210/trump-is-an-awful-person-but-he-isnt-a-competent" class="tumblr_blog">dog-of-ulthar</a>:</p>
<blockquote>
<p>Trump is an awful person, but he isn’t a competent politician.  Pence is possibly a <i>worse</i> person and a <i>very </i>competent politician.  <a href="http://thefederalist.com/2016/10/25/gop-needs-elect-trump-impeach/">There is already a conservative plan to impeach Trump so Pence can take the presidency.  </a></p>
<p>A Pence presidency probably has less chance of accidental nuclear war, but a much greater chance of extremely socially conservative legislation which would be devastating to civil rights in America.  Trump just wants to make money and feel important; Pence has an agenda.</p>
<p>Nixon was impeached for corruption.  We already know Trump is corrupt.  Bill Clinton was impeached for lying about inappropriate sexual conduct.  We already know Trump has lied about inappropriate sexual conduct.</p>
<p>It’s only a matter of time before he lies about something too big for his press aids to smooth over and Congress gets to have his way with him, because he is a mess of a man and makes mistakes, and makes them loud.</p>
<p>If Pence is allowed to take his place, Pence will not make the same mistakes.</p>
<p>Pence is a career politician.  He’s well-spoken.  He’s relatively attractive.  His positions are clear and well-established.  He has a law degree.  He’s on the conservative end of Republicans, but he’s a committed member of the party.  In everything that made Trump unpopular <i>among Republicans as well as Democrats</i>, Pence is the opposite.</p>
<p>There were jokes comparing Trump to Emperor Palpatine, and <a href="http://darthvidetur.tumblr.com/post/152972785590/trump-is-not-palpatine">a good rebuttal of them</a>.  Compared to Pence, Trump is Jar-Jar Binks.  Pence is Palpatine.</p>
<p>Trump is wildly unpopular because both liberals and the Republican establishment don’t like him.  He’s ugly and crass and obviously incompetent, he’s the <i>perfect </i>figurehead to rally <i>against</i>.</p>
<p>Pence is not.  Pence is dangerous in different ways, and one of the worst is that he won’t make nearly as good a symbol for his opponents.  If Trump gets kicked out, we have to keep protesting, even as people try to say that we got what we wanted, that everything can go back to normal.  </p>
<p>Remember this, when the impeachment happens, whether it’s a month from now or three years.  Trump is bad.  Pence might be worse.</p>
</blockquote>
<p>“A Pence presidency probably has less chance of accidental nuclear war,”<br/></p>
<p>“Trump is bad. Pence might be worse.”<br/></p>
<p>It seems like some people are less bothered by the idea of nuclear war than my friends and I am. </p>
</blockquote>
<p>This is the “flu during pregnancy doubles chances of schizophrenic children” thing. The base odds are so low we’re not really concerned by them.</p>
</blockquote>
<p>Pence was extruded out of the Generic Religious Conservative Republican Machine</p>
<p>he is a generic religious conservative republican</p>
<p>if the generic conservative republican is existentially terrifying, then then problem is with you. either you are so astonishingly self-centered that dealing with any opposition makes you enraged, or you are so astonishingly bad at politics that you have no ability to oppose measures you think are harmful and no ability to convince anyone that doesn’t already agree with you to do this, or both (for today’s left it is both)</p>
<p>pence will not be worse. pence has some measure of control over his emotions. pence has the ability to let minor symbolic slights against him pass beneath his notice. pence has comprehension of why human beings consider it important to say things that are true. </p>
<p>the only things pence wants to do are roll back some portion of the political victories your side won to an earlier state. a state where your team used to be able to do the actual work of convincing people, and attain those political victories. pence is not going to do damage in ways you cannot imagine and pence is not going to do damage to things you cannot imagine being damaged. pence will not do things that benefit absolutely nobody because he cannot control his emotions. pence will not use the force of the government to hunt down and punish people for saying mean things about him on twitter. pence is capable of perceiving <i>some aspect of reality</i> besides “how much do people like me, and should they be rewarded or punished for it”</p>
<p>these things cannot be said of trump</p>
<p>but the left will never notice this because the left is not capable of noticing this because all is devoured and all is lost. the left is devoured. entropy cannot be reversed. they are now a machine whose sole purpose is to give social power and emotional rewards to people that already have them. they will never again do something because it is useful or because it is correct. they will never again notice anything about the world beyond “the emotions of popular people”. they will not notice how trump is actually dangerous to american democracy in real life in the world because to them “dangerous to american democracy” is just a noise, like all other noises they make, that only means “give me power and emotional rewards”. all is lost. entropy cannot be reversed. all is lost.</p>
</blockquote>
<p>So, absolutely agreed and endorsed: Mike Pence is 100% Generic Extruded Religious-Conservative Republican Product.  He is not any kind of new unique monster.  He is not particularly different from any number of normal state-level Republican politicians.  <br/></p><p>Also agreed and endorsed: Trump <i>is </i>some kind of new unique monster, and his rise to power carries terrifying dangers that would not be posed by any normal politician, including his VP.  <br/></p><p>That said, I don’t think this analysis is fair.  I think you are underselling the extent to which it is possible to think, with integrity and with good reason, that Normal Partisan-Style Politics really matters.</p><p>Like, there are three categories of Horrible Things that we have to fear from the Trump presidency:</p><p>1. Horrible Things that we apparently have to fear from any presidency of any party because, Christ, apparently the system will co-opt anyone, even a guy like Barack Obama is not going to be your savior (e.g.: drone strikes, total failure to rein in abuses by the financial sector) <br/></p><p>2. Horrible Things that might arise from the personal idiosyncrasies of Donald Trump (e.g.: the streets of New York running red with blood because of a pogrom whose origins lay in a Twitter dustup with Taylor Swift)</p><p>3. Horrible Things that could be expected from any contemporary Republican administration but not from a Democratic administration</p><p>“How big is Category 3, especially compared to the other categories?” is a legitimate question whose answer is not inherently obvious.  <br/></p><p>I do in fact think that Category 3 is large.  I think that, for structural reasons that are not very hard to trace, the Republican Party has collectively gone off the deep end.  I think that standard Republican Party orthodoxy at this point involves policies &ndash; notably environmental, economic, and social-welfare policies &ndash; that are likely to be <i>catastrophically bad </i>for America and for the world (as opposed to Democratic Party orthodoxy, which is merely mildly bad).  I am honestly unsure whether the low-but-still-hideously-high threat of a Trump-fueled nuclear war matters more or less than the likelihood that Trump will act like a normal Republican most of the time. <br/></p><p>&hellip;you can point out, correctly, that we’re in a first-past-the-post system where the Republicans are one of the two major establishment parties, and therefore that they’re predictably going to win about half the things overall.  You can point out that about half the voters in the US, a group that obviously includes many many many good and decent people, are going to end up voting Republican for those same standard structural reasons.  None of these things is inconsistent with any of the others.  <br/></p><p><i>I</i> certainly think it all adds up to good and sufficient reason for feeling existential horror.  <br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/electoral%20politics>#electoral politics</a>
<a href=http://balioc.tumblr.com/tagged/because%20apparently%20this%20is%20what%20we%20talk%20about%20now>#because apparently this is what we talk about now</a>
 — 69764 notes — <a title=Source href=https://dog-of-ulthar.tumblr.com/post/156201449210/trump-is-an-awful-person-but-he-isnt-a-competent>dog-of-ulthar</a></footer>
</article>
<article class=text id=p-155748843771>
<header>
<p><time datetime=2017-01-12T04:31:41Z>01/11/2017 11:31:41 PM</time>
<a class=llink href=../posts/155748843771.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2H3Mi3x>●</a>
<a href=https://bambamramfan.tumblr.com/post/155741990607/excrucians>⬈</a>
</header>
<h2>Excrucians</h2>
<p><a href="http://bambamramfan.tumblr.com/post/155741990607/excrucians" class="tumblr_blog">bambamramfan</a>:</p><blockquote>
<blockquote>
<p>

The Deceivers live outside the world; they think that we have built the world out of lies. They think the whole of Creation
is a jungle of deceit that we have put up to keep from seeing ourselves the way we really are. </p>
<p>They love us but they love not that lie.

<br/></p>
</blockquote>
<p><a href="http://watermark.drivethrurpg.com/pdf_previews/104430-sample.pdf">

Nobilis: the Essentials, Volume 1 (Kindle Locations 4145-4157)

</a><br/></p>
<p>Which reminds me so much of Lacan</p>
<figure data-orig-height="272" data-orig-width="230"><img src="../media/tumblr_inline_ojn87msQuq1uw3n6e_1280.jpg" data-orig-height="272" data-orig-width="230"/></figure><blockquote><p>

Kinder Surprise, one of the most popular chocolate products on sale all around Central Europe, are empty egg shells made of chocolate and wrapped up in brightly colored foil; after one unwraps the egg and cracks the chocolate shell open, one finds in it a small plastic toy (or small parts from which a toy is to be put together). A child who buys this chocolate egg often nervously unwraps it and immediately breaks the chocolate, not bothering to eat it at first and worrying only about the toy in the center. Is such a chocolate-lover not a perfect case of French psychoanalyst Jacques Lacan’s dictum “I love you, but, inexplicably, I love something in you more than yourself, and, therefore, I destroy you”? And, effectively, is this toy not <i>l’objet petit a</i> at its purest, the small object filling in the central void of our desire, the hidden treasure, agalma, in the center of the thing we desire? 

<br/></p></blockquote>
<p><a href="http://www.cabinetmagazine.org/issues/11/kinderEgg.php">Zizek</a></p>
</blockquote>
<p>So, Zizek can laugh it up if he wants, but&hellip;</p><p>I’d never heard of Kinder Surprise until the year after college, when a friend of mine who’d just traveled to Europe introduced me to the concept.  It sounded kind of fun in a campy way, and there was a nearby imported-foods store, so I bought one on a lark.</p><p>The toy inside was <a href="https://www.catawiki.com/catalog/figures-statuettes-figurines-miniatures/collections-sets/mpg-c/2004301-monsignor-maximilian?area=15ff98c782ebe70f9139f960e93978c825b128b2">a little plastic rolly miniature of Cardinal Richelieu with what I can describe only as “Power Leering Action.” </a> <br/></p><p>So, <i>hells yeah</i>, the thing in the middle of a Kinder Surprise egg is <i>l’objet petit a</i>.  Quite rightly and sanely.  How could anything beat that, in terms of unimagined cosmic joy?  What better satiation of the vast fathomless hunger of human existence could there be?  <br/></p><p>(Needless to say, I never got anything nearly that awesome out of a Kinder Surprise egg again.)<br/></p>
<footer>29 notes</footer>
</article>
<article class=text id=p-155515257936>
<header>
<p><time datetime=2017-01-07T05:52:05Z>01/07/2017 12:52:05 AM</time>
<a class=llink href=../posts/155515257936.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2GrReHG>●</a>
</header>
<p>As far as I can tell, there are two kinds of writers in the world: the ones who dream of being great writers, and the ones who dream of being the kind of people they write about.</p>
<footer><a href=http://balioc.tumblr.com/tagged/neo-aphorisms>#neo-aphorisms</a>
 — 4 notes</footer>
</article>
<article class=text id=p-155448652026>
<header>
<p><time datetime=2017-01-05T20:34:02Z>01/05/2017 03:34:02 PM</time>
<a class=llink href=../posts/155448652026.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2GnTZ3w>●</a>
<a href=https://brazenautomaton.tumblr.com/post/155447007334/orbispelagium-orbispelagium-im-a-third-of>⬀</a>
<a href=https://cryptovexillologist.tumblr.com/post/155443900663/im-a-third-of-the-way-through-mascots-available>⬈</a>
</header>
<p><a href="http://brazenautomaton.tumblr.com/post/155447007334/orbispelagium-orbispelagium-im-a-third-of" class="tumblr_blog">brazenautomaton</a>:</p><blockquote>
<p><a href="http://orbispelagium.tumblr.com/post/155444500423/orbispelagium-im-a-third-of-the-way-through" class="tumblr_blog">orbispelagium</a>:</p>
<blockquote>
<p><a href="http://orbispelagium.tumblr.com/post/155443900663/im-a-third-of-the-way-through-mascots-available" class="tumblr_blog">orbispelagium</a>:</p>

<blockquote>
<p>I’m a third of the way through Mascots (available on Netflix), and it’s like it was designed to appeal to me specifically.</p>

<p>It’s nonstop dense, deadpan, absurdist dialogue that rarely belabors a joke, and it focuses on a group of weirdos without point-and-laugh cruelty, and it’s got a genuine affection for them (even in an interlude with furries appearing at the mascot competition).</p>

<p>It’s from the creator of This Is Spinal Tap, which I would have liked more if I was more versed in the last days of glam rock. This doesn’t have as many quotable classic jokes, but it’s good solid comedy throughout.</p>
</blockquote>

<p>Also, Zach Woods has such great energy/cadence/appearance for this kind of awkward deadpan comedy and he really needs to be in more things (he was amazing in In The Loop, and he even got to be in the new Ghostbusters as the tour guide at the start)</p>
</blockquote>
<p>I hated it, because I didn’t feel genuine affection at all. I felt that movie held all its characters save for the hedgehog guy in complete contempt; we are constantly seeing them do things the movie wants us to regard as dumb without letting us see them pay off or be vindicated. And unlike folk music or dog shows, mascotting is not built-up or glamorous, so the movie is looking down at people who are not highly regarded and saying “I need to take these guys down a few pegs.” Like, the sequence where one of the judges just goes on and on, unprompted, about having a small penis – and that’s it, that’s the joke, he has a small penis. For fuck’s sake, movie.</p>
</blockquote>
<p>I dunno.  I think that Guest’s work generally runs on an engine of “just sitting there and watching someone for enough time will humanize him and make you care, even if the narrative doesn’t provide a redemptive stinger.”  And I think it often works.  Not always, but often.  <br/></p><p>In <i>Mascots</i>, the plumber guy is probably the best example of this.  He’s a loser, we never see him being not-a-loser, and indeed we’re invited to laugh at the smallness of his world and the dumb things he cares about&hellip;but we see him trying hard, we see him reaching out to make a human connection, we see him being humiliated in a moment that should have been a triumph, and it’s <i>sad</i>.  It’s funny to some extent, but it’s definitely also sad, because by that point we’ve mapped some sad-sack part of ourselves onto this sad-sack dude and there is empathetic hurting.  <br/></p><p>You get the same thing to a lesser extent with Parker Posey’s character, who is obviously insane and clueless, but who is nonetheless shrouded in a weird humanistic dignity by the earnest purity of her passion.  (<i>Don’t you wish you were that insulated from existential dread?</i>, you can hear Guest whispering.  And, yeah, I kinda do.)  You even get it with the husband in the terrible marriage, because the script hammers you with “imagine if <i>you </i>were in a marriage like that,” and yeah, it’s terrible.</p><p>The Fist is indeed basically just a walking joke, though.<br/></p>
<footer>22 notes — <a title=Source href=https://cryptovexillologist.tumblr.com/post/155443900663/im-a-third-of-the-way-through-mascots-available>cryptovexillologist</a></footer>
</article>
<article class=text id=p-155272206546>
<header>
<p><time datetime=2017-01-02T01:09:26Z>01/01/2017 08:09:26 PM</time>
<a class=llink href=../posts/155272206546.html>¶</a>
<a href=https://tmblr.co/Zcl1wf2GcyTZI>●</a>
</header>
<p><b>BALIOC’S READING LIST, 2016 EDITION<br/></b></p><p>This list counts only published books, consumed in published-book format, that I read for the first time and finished.  No rereads, nothing abandoned halfway through, no Internet detritus of any kind, etc.<br/></p><p>1. <i>The Shepherd&rsquo;s Crown,</i> Terry Pratchett<br/>2. <i>Why We Love Serial Killers, </i>Scott Bonn<br/>3. <i>Zeus Grants Stupid Wishes,</i> Cory O'Brien<br/>4. <i>The Instructions, </i>Adam Levin<br/>5. <i>Otaku: Japan&rsquo;s Database Animals,</i> Hiroki Azuma<br/>6. <i>Gentleman Jole and the Red Queen, </i>Lois McMaster Bujold<br/>7. <i>The Bands of Mourning, </i>Brandon Sanderson<br/>8. <i>Mistborn: The Secret History, </i>Brandon Sanderson<br/>9. <i>The Great Exception: The New Deal and the Limits of American Politics, </i>Jefferson Cowie<br/>10. <i>Calamity, </i>Brandon Sanderson<br/>11. <i>American Pastoral, </i>Philip Roth<br/>12. <i>This Census-Taker, </i>China Mieville<br/>13. <i>The Secrets of Drearcliff Grange School, </i>Kim Newman<br/>14. <i>Nations and Nationalism, </i>Ernst Gellner<br/>15. <i>The Guns of Ivrea, </i>Clifford Beal<br/>16. <i>Shadow&rsquo;s Edge, </i>Brent Weeks<br/>17. <i>The Library at Mount Char, </i>Scott Hawkins<br/>18. <i>Phantastes: A Faerie Romance for Men and Women, </i>George MacDonald<br/>19. <i>The Book of the Beast, </i>Tanith Lee<br/>20. <i>Beyond the Shadow, </i>Brent Weeks<br/>21. <i>The Book of the Dead, </i>Tanith Lee<br/>22. <i>The Book of the Mad, </i>Tanith Lee<br/>23. <i>Courtesans and Fishcakes: The Consuming Passions of Classical Athens</i>, James N. Davidson<br/>24. <i>American Nations: A History of the Eleven Rival Regional Cultures of North America, </i>Colin Woodard<br/>25. <i>The Girl Who Circumnavigated Fairyland In a Ship of Her Own Making, </i>Catherynne Valente<br/>26. <i>The Girl Who Fell Beneath Fairyland and Led the Revels There, </i>Catherynne Valente<br/>27. <i>The Girl Who Soared Over Fairyland and Cut the Moon In Two, </i>Catherynne Valente<br/>28. <i>Children of Earth and Sky, </i>Guy Gavriel Kay<br/>29. <i>Being Mortal: Medicine and What Matters In the End, </i>Atul Gawande<br/>30. <i>A Voyage To Arcturus, </i>David Lindsay<br/>31. <i>In the Labyrinth of Drakes, </i>Marie Brennan<br/>32. <i>The Gun Seller, </i>Hugh Laurie<br/>33. <i>Never Let Me Go, </i>Kazuo Ishiguro<br/>34. <i>The Goblin Emperor, </i>Katherine Addison<br/>35. <i>Penric and the Shaman, </i>Lois McMaster Bujold<br/>36. <i>The Hallowed Hunt, </i>Lois McMaster Bujold<br/>37. <i>The Great Ordeal, </i>R. Scott Bakker<br/>38. <i>The Book of Heroes, </i>Miyuki Miyabe<br/>39. <i>Psmith In the City, </i>P. G. Wodehouse<br/>40. <i>Last First Snow, </i>Max Gladstone<br/>41. <i>Harry Potter and the Cursed Child, </i>Jack Thorne<br/>42. <i>The Drug Wars in America, 1940-1973, </i>Kathleen J. Fryol<br/>43. <i>Sapiens: A Brief History of Humankind, </i>Yuval Noah Harari<br/>44. <i>Four Roads Cross, </i>Max Gladstone<br/>45. <i>Best. State. Ever.: A Florida Man Defends His Homeland, </i>Dave Barry<br/>46. <i>Midnight in the Garden of Good and Evil, </i>John Berendt<br/>47. <i>For All the Tea in China: How England Stole the World&rsquo;s Favorite Drink and Changed History, </i>Sarah Rose<br/>48. <i>The Politeness of Princes and Other School Stories, </i>P. G. Wodehouse<br/>49. <i>Tales of St. Austin&rsquo;s,</i> P. G. Wodehouse<br/>50. <i>When a Fan Hits the Shit: The Rise and Fall of a Phony Charity, </i>Jeanine Renne<br/>51. <i>Killer of Men, </i>Christian Cameron<br/>52. <i>Marathon, </i>Christian Cameron<br/>53. <i>Poseidon&rsquo;s Spear, </i>Christian Cameron<br/>54. <i>Debt: The First 5,000 Years, </i>David Graeber<br/>55. <i>The Great King, </i>Christian Cameron<br/>56. <i>Salamis, </i>Christian Cameron<br/>57. <i>The Ill-Made Knight, </i>Christian Cameron<br/>58. <i>The Long Sword, </i>Christian Cameron<br/>59. <i>Strangers in Their Own Land: Anger and Mourning on the American Right, </i>Arlie Russell Hochschild<br/>60. <i>Penric&rsquo;s Mission, </i>Lois McMaster Bujold<br/>61. <i>Mister Monkey, </i>Francine Prose<br/>62. <i>Hell&rsquo;s Angels: A Strange and Terrible Saga, </i>Hunter S. Thompson<br/>63. <i>Decline and Fall: The End of Empire and the Future of Democracy in 21st Century America, </i>John Michael Greer<br/>64. <i>Rage of Ares, </i>Christian Cameron<br/>65. <i>The Dragon&rsquo;s Path, </i>Daniel Abraham</p><p>

“Full-length” works consumed in 2016: 54</p><p>Works consumed in 2016 that are maybe too short to count (novellas, etc.): 11</p><p>Plausible works of improving nonfiction consumed in 2016: 14</p><p>Works consumed in 2016 written by women: 18</p><p>Works consumed in 2016 written by men: 47<br/></p><p>Balioc’s Choice Award, fiction division: <i>The Instructions</i></p><p>Balioc’s Choice Award, nonfiction division: <i>Debt: The First 5,000 Years</i></p><p>&hellip;I feel like the takeaway here <i>should </i>be “less genre stuff and more Serious Books About the Real World.”  Seeing my improving-nonfiction count sitting at 14 is <i>painful</i>.  But, man, reading fantasy novels is great and it’s hard to feel too bad about doing a lot of it.  <br/></p>
<footer><a href=http://balioc.tumblr.com/tagged/yearly%20reading%20list>#yearly reading list</a>
 — 8 notes</footer>
</article>
<footer><nav><a href=../index.html rel=index>Index</a>
| <a href=2017-02-p1.html rel=prev>Previous</a>
| <a href=2016-12-p1.html rel=next>Next</a>
</nav></footer>

<!DOCTYPE html>

<meta charset=utf-8>
<title>Second Balcony</title>
<link rel=stylesheet href=../backup.css>

<body class=archive>

<header>
<h1>December 2015</h1>
</header>

<article class=text id=p-135209524668>
<header>
<p><time datetime=2015-12-14T22:06:36Z>12/14/2015 05:06:36 PM</time>
<a class=llink href=../posts/135209524668.html>¶</a>
<a href=https://tmblr.co/ZW8hPy1zx7Psy>●</a>
</header>
<p>The central proposition of my dissertation is, informally, &lsquo;it&rsquo;s possible to learn a way of seeing by examining a group of objects that this way of seeing sees the best.&rsquo; I take my cue from how representation-learning neural nets learn not only a low dimensional representation space, but also a projection from each point in input-space to some point in a low dimensional submanifold <i>within the input </i><i>space</i><b><i>.</i></b></p><p> Typically, deep learning researchers are only interested in this projection function in the training stage, where it&rsquo;s used as a proxy for the low dimensional representation space: they employ the distance between input and projection (on the training data) as an optimization goal, and when the training&rsquo;s finished they extract the low dimensional representation space this training has effected. As someone studying the arts, however, my interest stays with the submanifold in input-space &ndash; that is, the set of input-space points the trained neural net learned to project into.  This set has four technical properties that, while individually obvious, are deeply interesting when taken all together: </p><ol><li>It&rsquo;s the set of all the inputs that the trained net can compressedly encode with zero loss.<br/></li><li>All input reconstructions by the trained net will replace the original input with an element of this set. </li><li>If the net&rsquo;s training was successful, the objects in this set exemplify a specific high-fidelity simplification of the objects generated by the distribution underlying the training data. </li><li>A neural net trained on this set as input will approximate the neural net that generated it.</li></ol><p>Speaking informally, these properties almost explicitly describe art as we know it: an individual apprehends the world in a particular lossy way that is partly adapted to her formative environment, she produces a mimesis of the world that is more simple than the world in a specific way that bears the mark of her particular lossy apprehension of the world, and other individuals can learn her apprehension of the world by trying to very exactingly apprehend the artefactual world she produced. Basically, when we deal with cognitive systems that you can&rsquo;t crack open &ndash; like in humans, and unlike in practical deep learning research &ndash; the image of a cognitive system&rsquo;s projection function becomes the most direct accessible manifestation of its representation space, and the concrete (or, in the case of literature, imaginative) realization of this image by mimesis of the world becomes a key method for communicating the representation space. Also important is the near-equivalence this draws between producing a mimesis of the world and presenting a selection of near-losslessly compressible objects from the world: this near-equivalence offers us a way to understand curation, installation, collage, and other Modernist practices that are not prima facie mimetic as nevertheless communicating a representation space. </p><p>Speaking more formally, these properties suggest a method for communicating high-fidelity compression schemas between agents, and a reason to believe this method has advantages over training each agent individually: assume a neural network x that has a high-fidelity compression schema for a distribution D, and an untrained neural net y that we want to train to have a high-fidelity compression schema for D. Assume, now, for the sake of an analogy with humans, that the internal structure of the neural nets is read/write inaccessible. If D is fairly hard to learn, the efficient and reliable solution is to train y on a dataset of x&rsquo;s reconstructions of inputs from D, instead of training y directly on inputs from D. The actual model I&rsquo;m proposing deals with works of art as methods for communicating a representation space to learners that already have a relatively advanced representation space to start with, rather than as methods of communicating it to a blank slate learner, but I hope this illustrates the general idea. </p>
<footer>19 notes</footer>
</article>
<article class=text id=p-134748038003>
<header>
<p><time datetime=2015-12-07T21:49:11Z>12/07/2015 04:49:11 PM</time>
<a class=llink href=../posts/134748038003.html>¶</a>
<a href=https://tmblr.co/ZW8hPy1zVc_Dp>●</a>
</header>
<p>Q: What does Rousseau&rsquo;s OkCupid profile page say?<br/>A: &ldquo;I hate drama&rdquo;<br/></p>
<footer>5 notes</footer>
</article>
<article class=text id=p-134396762483>
<header>
<p><time datetime=2015-12-02T13:57:46Z>12/02/2015 08:57:46 AM</time>
<a class=llink href=../posts/134396762483.html>¶</a>
<a href=https://tmblr.co/ZW8hPy1zAgzbp>●</a>
</header>
<p><b>My Research in One Sentence<br/></b><br/>You can learn a way of seeing by examining a group of objects that this way of seeing sees the best. </p>
<footer>4 notes</footer>
</article>
<footer><nav><a href=../index.html rel=index>Index</a>
| <a href=2016-01-p1.html rel=prev>Previous</a>
| <a href=2015-11-p1.html rel=next>Next</a>
</nav></footer>
